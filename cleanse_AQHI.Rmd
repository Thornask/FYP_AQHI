# requiring 
```{r}
# install.packages("tidyverse")
require("tidyverse")
require("readr")
require("Hmisc")
```

# Import (Raw data)
```{r}
# 1.roadside_CausewayBay

roadside_CausewayBay <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_CausewayBay_roadside_01011998_06302022.csv")

# 2.roadside_Central

roadside_Central <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_Central_roadside_01011999_06302022.csv")

# 3.CentralWest

CentralWest <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_CentralWestern_01011990_06302022.csv")

# 4.Eastern

Eastern <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_Eastern_01011999_06302022.csv")

# 5.KwaiChung

KwaiChung <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_KwaiChung_01011990_06302022.csv")

# 6.KwunTong

KwunTong <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_KwunTong_01011990_06302022.csv")

# 7.roadside_MongKok

roadside_MongKok <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_MongKok_roadside_04011991_06302022.csv")

# 8.North

North <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_North_07102020_06302022.csv")

# 9.ShamShuiPo

ShamShuiPo <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_ShamShuiPo_01011990_06302022.csv")

# 10.ShaTin

ShaTin <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_ShaTin_07011991_06302022.csv")

# 11.Southern

Southern <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_Southern_07102020_06302022.csv")

# 12.TaiPo

TaiPo <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_TaiPo_02011990_06302022.csv")

# 13.TapMun

TapMun <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_TapMun_04011998_06302022.csv")

# 14.TseungKwanO

TseungKwanO <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_TseungKwanO_03162016_06302022.csv")

# 15.TsuenWan

TsuenWan <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_TsuenWan_01011990_06302022.csv")

# 16.TuenMun

TuenMun <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_TuenMun_01012014_06302022.csv")

# 17.TungChung

TungChung <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_TungChung_04011999_06302022.csv")

# 18.YuenLong

YuenLong <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\in_station(-06302022)\\air_hourly_YuenLong_08011995_06302022.csv")

```

# Cleanse(1)
```{r}
# all <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\all.csv")

# Combine data as one dataset
all <- do.call("rbind", list(CentralWest, Eastern, KwaiChung, KwunTong, North, roadside_CausewayBay, roadside_Central, roadside_MongKok, ShamShuiPo, ShaTin, Southern, TaiPo, TapMun, TseungKwanO, TsuenWan, TuenMun, TungChung, YuenLong))

# Remove the unused dataset to release memories
rm(CentralWest, Eastern, KwaiChung, KwunTong, North, roadside_CausewayBay, roadside_Central, roadside_MongKok, ShamShuiPo, ShaTin, Southern, TaiPo, TapMun, TseungKwanO, TsuenWan, TuenMun, TungChung, YuenLong)

# Change the Chinese character to English
colnames(all)[which(names(all) == "日期")] <- "date"
colnames(all)[which(names(all) == "小時")] <- "hour"
colnames(all)[which(names(all) == "監測站")] <- "station"
# ... and remove unnecessary value
temp_all <- all
temp_all[, c("NOX", "CO")] <- list(NULL) 
temp_all[, c('FSP', 'NO2', 'O3', 'RSP', 'SO2')] <- temp_all[, c('NO2', 'SO2', 'O3', 'RSP', 'FSP')]
colnames(temp_all)[-1:-3] <- c('NO2', 'SO2', 'O3', 'RSP', 'FSP')
# (cont.) Change the Chinese character to English
station_chName <- unique(all$station)
station_egName <- c('CentralWest', 'Eastern', 'KwaiChung', 'KwunTong', 'North', 'roadside_CausewayBay', 'roadside_Central', 'roadside_MongKok', 'ShamShuiPo', 'ShaTin', 'Southern', 'TaiPo', 'TapMun', 'TseungKwanO', 'TsuenWan', 'TuenMun', 'TungChung', 'YuenLong')

sapply(station_chName, function(x){
  if(any(temp_all$station == x)) {
    temp_all$station[temp_all$station==x] <<- station_egName[which(station_chName == x)]
    }
  })

# general <- subset(temp_all, temp_all$station != 'roadside_CausewayBay' 
#                   & temp_all$station != 'roadside_Central' 
#                   & temp_all$station != 'roadside_MongKok')
# roadside <- subset(temp_all, temp_all$station == 'roadside_CausewayBay' 
#                    | temp_all$station == 'roadside_Central' 
#                    | temp_all$station == 'roadside_MongKok')

# Export
write_excel_csv(temp_all, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\all.csv")
# write_excel_csv(roadside, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\roadside.csv")
# write_excel_csv(general, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\general.csv")
```

# Cleanse(2)
```{r}
# temp_all <- read_csv("C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\all.csv")

# Set date to POSIX date (ISOdate), and add a column "HKTdate" for reference
temp_all$date <- as.Date(temp_all$date, format = "%d/%m/%Y")
temp_all$date <- ISOdate(temp_all$date, as.numeric(temp_all$hour),0,0)
temp_all <- subset(temp_all, select = -hour)
# Change the "N.A." value to null
temp_all$NO2 <- str_remove_all(temp_all$NO2,"N.A.")
temp_all$SO2 <- str_remove_all(temp_all$SO2,"N.A.")
temp_all$O3 <- str_remove_all(temp_all$O3,"N.A.")
temp_all$FSP <- str_remove_all(temp_all$FSP,"N.A.")
temp_all$RSP <- str_remove_all(temp_all$RSP,"N.A.")
# Correct the data type of pollutant
temp_all$NO2 <- as.numeric(temp_all$NO2)
temp_all$SO2 <- as.numeric(temp_all$SO2)
temp_all$O3 <- as.numeric(temp_all$O3)
temp_all$RSP <- as.numeric(temp_all$RSP)
temp_all$FSP <- as.numeric(temp_all$FSP)

# Export
write_excel_csv(temp_all, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\all_with_NULL.csv")

# Cross out the data which the AQHI can't be calculated because of the missing value
# noNa_all <- subset(temp_all, !(is.na(temp_all$NO2)|is.na(temp_all$SO2)|is.na(temp_all$O3)|(is.na(temp_all$RSP)&is.na(temp_all$FSP))))

# Export
# write_excel_csv(noNa_all, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\all_wo_NULL.csv")

```

# Export (by stations)
```{r}
# separate data by station 
df <-temp_all
for(sel_name in station_egName){
  sel_df <- df[df$station == sel_name, ]
  assign(sel_name, subset(sel_df, select = -station))
}
rm(df, sel_df)

# export
write_excel_csv(roadside_CausewayBay, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\roadside_CausewayBay.csv")
write_excel_csv(roadside_Central, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\roadside_Central.csv")
write_excel_csv(CentralWest, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\CentralWest.csv")
write_excel_csv(Eastern, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\Eastern.csv")
write_excel_csv(KwaiChung, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\KwaiChung.csv")
write_excel_csv(KwunTong, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\KwunTong.csv")
write_excel_csv(roadside_MongKok, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\roadside_MongKok.csv")
write_excel_csv(North, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\North.csv")
write_excel_csv(ShamShuiPo, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\ShamShuiPo.csv")
write_excel_csv(ShaTin, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\ShaTin.csv")
write_excel_csv(Southern, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\Southern.csv")
write_excel_csv(TaiPo, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\TaiPo.csv")
write_excel_csv(TapMun, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\TapMun.csv")
write_excel_csv(TseungKwanO, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\TseungKwanO.csv")
write_excel_csv(TsuenWan, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\TsuenWan.csv")
write_excel_csv(TuenMun, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\TuenMun.csv")
write_excel_csv(TungChung, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\TungChung.csv")
write_excel_csv(YuenLong, "C:\\Users\\user\\OneDrive\\Documents\\AQHI data\\cleansed_dataset\\YuenLong.csv")

# Remove the unused dataset to release memories
rm(CentralWest, Eastern, KwaiChung, KwunTong, North, roadside_CausewayBay, roadside_Central, roadside_MongKok, ShamShuiPo, ShaTin, Southern, TaiPo, TapMun, TseungKwanO, TsuenWan, TuenMun, TungChung, YuenLong)
```

# subset a sample data from one station
```{r}
# filter the data from one of the station
sel_name <- "CentralWest"
assign(sel_name, subset(temp_all, temp_all$station == sel_name))
```

# (for uploading)
```{r}
# install.packages("git2rdata")
# require("git2rdata")
# df1 <- do.call("rbind", list(CentralWest, Eastern, KwaiChung, KwunTong, North, roadside_CausewayBay, roadside_Central, roadside_MongKok, ShamShuiPo))
# df2 <-  do.call("rbind", list(ShaTin, Southern, TaiPo, TapMun, TseungKwanO, TsuenWan, TuenMun, TungChung, YuenLong))

```


# note:
```{r}
## 每小時的空氣質素健康指數，是根據四種主要空氣污染物，包括臭氧(O3)、二氧化氮(NO2)、二氧化硫(SO2)和懸浮粒子(PM) [可吸入懸浮粒子(RSP 或 PM10) 或 微細懸浮粒子(FSP 或 PM2.5)，以健康風險較大者為準)] 的三小時移動平均污染物濃度，以估算四種空氣污染物所導致入院的個別健康風險增幅的總和(%AR) 而轉化得出。個別空氣污染物的健康風險增幅，視乎該污染物的濃度和從分析本地健康統計數字和空氣污染數據而得出的風險系數。健康風險增幅會與一個空氣質素健康指數的等級表對照，以釐定空氣質素健康指數級別。計算公式如下:

## 健康風險增幅(%AR) = %AR (NO2) + %AR (SO2) + %AR (O3) + %AR (PM)

## %AR (PM) = %AR (PM10) 或 %AR (PM2.5), 以風險較大者為準

## %AR(NO2) = [exp (β(NO2) × C(NO2)) – 1] × 100%
## %AR(SO2) = [exp (β(SO2) × C(SO2)) – 1] × 100%
## %AR(O3) = [exp (β(O3) × C(O3)) – 1] × 100%
## %AR(PM10) = [exp (β(PM10) × C(PM10)) – 1] × 100%
## %AR(PM2.5) = [exp (β(PM2.5) × C(PM2.5)) – 1] × 100%

## 公式中-

## %AR(NO2), %AR (SO2), %AR (O3), %AR (PM), %AR (PM10) 及 %AR (PM2.5)分別是二氧化氮、二氧化硫、臭氧、懸浮粒子、可吸入懸浮粒子和微細懸浮粒子的個別健康風險增幅;

## C(NO2), C(SO2), C(O3), C(PM10) 及 C(PM2.5) 是各污染物的三小時移動平均濃度(以微克/立方米計)(ug/m3); 及

## β(NO2), β(SO2), β(O3), β(PM10) 及 β(PM2.5) 是各污染物的風險系數 (即學術上的回歸系數)

## β(NO2) = 0.0004462559
## β(SO2) = 0.0001393235
## β(O3) = 0.0005116328
## β(PM10) = 0.0002821751
## β(PM2.5) = 0.0002180567

```
